{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Tensorflow_VGG16_arch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"dazUbYDNSIOj"},"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","from keras.utils import np_utils\n","import numpy as np\n","import cv2\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","import random\n","np.random.seed(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBRnM-Wzkh83"},"source":["################################################load data and process################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQj4EuIGwMHK"},"source":["#padding with 0 to get 1:1 size ratio\n","def img_padding(img):\n","    x, y = img.shape\n","    size_diff = abs(x-y)\n","    pad_size = int(size_diff/2)\n","    if(x>y):\n","        pad = np.zeros((x, pad_size),dtype=int)\n","        img_1_1 = np.concatenate((pad,img,pad), axis = 1)\n","        if(size_diff%2 != 0):\n","            pad1 = np.zeros((x, 1),dtype=int)\n","            img_1_1 = np.concatenate((img_1_1,pad1), axis = 1)\n","    elif(y>x):\n","        pad = np.zeros((pad_size, y),dtype=int)\n","        img_1_1 = np.concatenate((pad,img,pad), axis = 0)\n","        if(size_diff%2 != 0):\n","            pad1 = np.zeros((1, y),dtype=int)\n","            img_1_1 = np.concatenate((img_1_1,pad1), axis = 0)\n","    else:\n","        img_1_1 = img\n","\n","    return img_1_1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDbLPogjrQJk"},"source":["# this function is for read image,the input is directory name (for RGB)    \n","def read_directory(directory_name):\n","    array_of_img = [] # this if for store all of the image data\n","    dim = (224,224)\n","    # this loop is for read each image in this foder,directory_name is the foder name with images.\n","    for filename in os.listdir(r\"./\"+directory_name):\n","        #print(filename) #just for test\n","        #img is used to store the image data \n","        img = cv2.imread(directory_name + \"/\" + filename, cv2.IMREAD_GRAYSCALE)\n","        img = img_padding(img)\n","        img = img.astype(np.uint8)\n","        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","        array_of_img.append(img)\n","    return array_of_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1iqfJMmrQJl"},"source":["#read feature\n","truck_X = read_directory(\"training_imgs/RGB_imgs/cap\")\n","truck_X = np.asarray(truck_X)\n","truck_X = truck_X.reshape((len(truck_X), 224, 224, 1))\n","forklift_X = read_directory(\"training_imgs/RGB_imgs/flashlight\")\n","forklift_X = np.asarray(forklift_X)\n","forklift_X = forklift_X.reshape((len(forklift_X), 224, 224, 1))\n","negative_X = read_directory(\"training_imgs/RGB_imgs/soda_can\")\n","negative_X = np.asarray(negative_X)\n","negative_X = negative_X.reshape((len(negative_X), 224, 224, 1))\n","\n","print(truck_X.shape)\n","print(forklift_X.shape) \n","print(negative_X.shape)\n","\n","print(type(negative_X))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8ZIbFnVrQJm"},"source":["#############################################feature################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yM3VtxRXrQJn"},"source":["#traning and testing feature\n","#you can choose the training and testing data by this (by assign)\n","#or use the \"train_test_split\" function from sklearn.model as down below\n","truck_X_train = truck_X[-100:]\n","truck_X_test = truck_X[0:100]\n","forklift_X_train = forklift_X[-100:]\n","forklift_X_test = forklift_X[0:100]\n","negative_X_train = negative_X[-100:]\n","negative_X_test = negative_X[0:100]\n","\n","print(truck_X_train.shape, truck_X_test.shape)\n","print(forklift_X_train.shape, forklift_X_test.shape)\n","print(negative_X_train.shape, negative_X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LChEzp2SrQJn"},"source":["#concatenate 4 categories into training and testing feature\n","train_X = np.concatenate(( truck_X_train, forklift_X_train, negative_X_train), axis=0)\n","test_X = np.concatenate(( truck_X_test, forklift_X_test, negative_X_test), axis=0)\n","print(train_X.shape, test_X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDFPnvyVrQJo"},"source":["#############################################label################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWPA91ZUrQJo"},"source":["#training and testing label\n","truck_Y_train = np.ones(truck_X_train.shape[0])*0\n","truck_Y_test = np.ones(truck_X_test.shape[0])*0\n","\n","forklift_Y_train = np.ones(forklift_X_train.shape[0])*1\n","forklift_Y_test = np.ones(forklift_X_test.shape[0])*1\n","\n","negative_Y_train = np.ones(negative_X_train.shape[0])*2\n","negative_Y_test = np.ones(negative_X_test.shape[0])*2\n","\n","\n","print(truck_Y_train.shape, truck_Y_test.shape)\n","print(forklift_Y_train.shape, forklift_Y_test.shape)\n","print(negative_Y_train.shape, negative_Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCTGnmBUrQJp"},"source":["#concatenate 4 categories into training and testing label\n","train_Y = np.concatenate(( truck_Y_train, forklift_Y_train, negative_Y_train), axis=0)\n","test_Y = np.concatenate(( truck_Y_test, forklift_Y_test, negative_Y_test), axis=0)\n","print(train_Y.shape, test_Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdo5yzbhrQJq"},"source":["#############################################shuffle################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AeoHxspdrQJq"},"source":["#shuffle the training feature and label\n","temp = list(zip(train_X, train_Y))\n","random.shuffle(temp)\n","train_X, train_Y = zip(*temp)\n","train_X = np.asarray(train_X)\n","train_Y = np.asarray(train_Y)\n","print(train_X.shape, train_Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qulceBlarQJr"},"source":["#shuffle the testing feature and label\n","temp = list(zip(test_X, test_Y))\n","random.shuffle(temp)\n","test_X, test_Y = zip(*temp)\n","test_X = np.asarray(test_X)\n","test_Y = np.asarray(test_Y)\n","print(test_X.shape, test_Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FR0d-u8rQJr"},"source":["#reform training and testing label into one hot format\n","train_Y_onehot = np_utils.to_categorical(train_Y)\n","test_Y_onehot = np_utils.to_categorical(test_Y)\n","print(train_Y_onehot.shape, test_Y_onehot.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTMC_pf0rQJs"},"source":["#############################################split to get validation data################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNfwuM9prQJs"},"source":["from sklearn.model_selection import train_test_split\n","train_images, validation_images, train_labels, validation_labels = train_test_split(train_X, train_Y_onehot, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_K9AVNIfRrN"},"source":["print('train imgs:', train_images.shape, 'labels:', train_labels.shape)\n","print('validation imgs:', validation_images.shape, 'labels:', validation_labels.shape)\n","print('test imgs:', test_X.shape, 'labels:', test_Y_onehot.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYtM4T4jh84O"},"source":["#############################################define model funtions, dense, conv2d and mas_pooling#############################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_WPUwGaavO0"},"source":["def layer(output_dim, input_dim, inputs, activation=None):  #dense for MLP\n","  W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n","  b = tf.Variable(tf.random_normal([1, output_dim]))\n","  XWb = tf.matmul(inputs, W) + b\n","  if activation is None:\n","    outputs = XWb\n","  else:\n","    outputs = activation(XWb)\n","  return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yPP2MkRcMcIk"},"source":["def dropout(h):  #dropout\n","  return tf.nn.dropout(h, rate=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGK1PCnxcTmk"},"source":["def weight(shape):  #conv2d\n","  return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n","\n","def bias(shape):\n","  return tf.Variable(tf.constant(0.1, shape=shape))\n","\n","def conv2d(x, W, b):\n","  return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')+b "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZ53wDiVloCy"},"source":["def max_pool_2x2(x):\n","  return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pnVewTkbA70"},"source":["#############################################model training#############################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO2W4m-znXkZ"},"source":["#build CNN model\n","x = tf.placeholder(\"float\", [None, 224, 224, 1])\n","#conv block 1\n","W1_1 = weight([3,3,1,64])\n","b1_1 = bias([64])\n","conv1_1 = tf.nn.relu(conv2d(x, W1_1, b1_1))\n","\n","W1_2 = weight([3,3,64,64])\n","b1_2 = bias([64])\n","conv1_2 = tf.nn.relu(conv2d(conv1_1, W1_2, b1_2))\n","\n","C1_pool = max_pool_2x2(conv1_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLRH_bMPa26b"},"source":["#conv block 2\n","W2_1 = weight([3,3,64,128])\n","b2_1 = bias([128])\n","conv2_1 = tf.nn.relu(conv2d(C1_pool, W2_1, b2_1))\n","\n","W2_2 = weight([3,3,128,128])\n","b2_2 = bias([128])\n","conv2_2 = tf.nn.relu(conv2d(conv2_1, W2_2, b2_2))\n","\n","C2_pool = max_pool_2x2(conv2_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WPYd4Baya2mv"},"source":["#conv block 3\n","W3_1 = weight([3,3,128,256])\n","b3_1 = bias([256])\n","conv3_1 = tf.nn.relu(conv2d(C2_pool, W3_1, b3_1))\n","\n","W3_2 = weight([3,3,256,256])\n","b3_2 = bias([256])\n","conv3_2 = tf.nn.relu(conv2d(conv3_1, W3_2, b3_2))\n","\n","W3_3 = weight([3,3,256,256])\n","b3_3 = bias([256])\n","conv3_3 = tf.nn.relu(conv2d(conv3_2, W3_3, b3_3))\n","\n","C3_pool = max_pool_2x2(conv3_3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jpmFs8Ta2Ue"},"source":["#conv block 4\n","W4_1 = weight([3,3,256,512])\n","b4_1 = bias([512])\n","conv4_1 = tf.nn.relu(conv2d(C3_pool, W4_1, b4_1))\n","\n","W4_2 = weight([3,3,512,512])\n","b4_2 = bias([512])\n","conv4_2 = tf.nn.relu(conv2d(conv4_1, W4_2, b4_2))\n","\n","W4_3 = weight([3,3,512,512])\n","b4_3 = bias([512])\n","conv4_3 = tf.nn.relu(conv2d(conv4_2, W4_3, b4_3))\n","\n","C4_pool = max_pool_2x2(conv4_3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEHLpSEBeyfI"},"source":["#conv block 5\n","W5_1 = weight([3,3,512,512])\n","b5_1 = bias([512])\n","conv5_1 = tf.nn.relu(conv2d(C4_pool, W5_1, b5_1))\n","\n","W5_2 = weight([3,3,512,512])\n","b5_2 = bias([512])\n","conv5_2 = tf.nn.relu(conv2d(conv5_1, W5_2, b5_2))\n","\n","W5_3 = weight([3,3,512,512])\n","b5_3 = bias([512])\n","conv5_3 = tf.nn.relu(conv2d(conv5_2, W5_3, b5_3))\n","\n","C5_pool = max_pool_2x2(conv5_3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0fqyFXva2v1"},"source":["#fully connected layers\n","D_flat = tf.reshape(C5_pool, [-1,512*7*7])\n","\n","W_D1 = weight([512*7*7, 4096])\n","b_D1 = bias([4096])\n","D1_Hidden = tf.nn.relu(tf.matmul(D_flat,W_D1)+b_D1)\n","\n","W_D2 = weight([4096, 4096])\n","b_D2 = bias([4096])\n","D2_Hidden = tf.nn.relu(tf.matmul(D1_Hidden,W_D2)+b_D2)\n","\n","W_D3 = weight([4096, 3])\n","b_D3 = bias([3])\n","y_predict = tf.nn.softmax(tf.matmul(D2_Hidden,W_D3)+b_D3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gXIM7tqVPADu"},"source":["#training method\n","y_label = tf.placeholder('float', [None, 3])\n","loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_predict, labels=y_label))\n","optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss_function)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2uFTOckT_Al"},"source":["#accuracy Evaluation method\n","correct_prediction = tf.equal(tf.argmax(y_label, 1), tf.argmax(y_predict, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aHHe9K9Uq71"},"source":["#start training\n","trainEpochs = 10\n","batchSize = 100\n","totalbatch = int(len(train_images)/batchSize)\n","loss_list = []; epoch_list = []; accuracy_list = []\n","from time import time\n","startTime=time()\n","\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kqVh3W_WS5O"},"source":["for epoch in range(trainEpochs):\n","  for i in range(totalbatch):\n","    batch_x = train_images[i*batchSize:(i+1)*batchSize]\n","    batch_y = train_labels[i*batchSize:(i+1)*batchSize]\n","    sess.run(optimizer, feed_dict={x: batch_x, y_label: batch_y})\n","  \n","  loss, acc = sess.run([loss_function, accuracy], feed_dict={x: validation_images, y_label: validation_labels})\n","\n","  epoch_list.append(epoch)\n","  loss_list.append(loss)\n","  accuracy_list.append(acc)\n","  print(\"Train Epoch:\", '%02d' %(epoch+1), \"Loss=\", \"{:.9f}\".format(loss), \"Accuracy=\", acc)\n","\n","duration = time() - startTime\n","print(\"Training Time\", duration)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FzEpBwbegH0"},"source":["#accuracy of testing data \n","#print(\"Accuracy:\", sess.run(accuracy, feed_dict={x: test_X, y_label: test_Y_onehot}))\n","batch_test = 10\n","totalbatch_test = int(len(test_X)/batch_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6eUH0mcGiok"},"source":["t_total_acc = 0\n","for i in range(totalbatch_test):\n","    test_batch_x = test_X[i*batch_test:(i+1)*batch_test]\n","    test_batch_y = test_Y_onehot[i*batch_test:(i+1)*batch_test]\n","\n","    t_batch_acc = sess.run(accuracy, feed_dict={x: test_batch_x, y_label: test_batch_y})\n","    t_total_acc = t_total_acc + t_batch_acc\n","\n","t_total_acc = t_total_acc/totalbatch_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWjO7EweaeeM"},"source":["print(t_total_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrXKo-0CLWJS"},"source":["\"\"\"#predict the testing data and see the real label\n","prediction_result = sess.run(tf.argmax(y_predict,1), feed_dict={x: test_images})\n","print(prediction_result[:10])\n","real_num = np.argmax(test_labels, axis=1)\n","print(real_num[:10])\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TyvwTV9_MFO1"},"source":[""],"execution_count":null,"outputs":[]}]}